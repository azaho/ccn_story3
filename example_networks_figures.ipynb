{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "041aa425-dadf-4d6c-a945-994c76b54804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, json, time, random\n",
    "import hashlib, torch, math, pathlib\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from scipy.optimize import curve_fit\n",
    "import importlib, importlib.util, os\n",
    "\n",
    "targetinput_color = \"#006838\"\n",
    "distractor_color = \"#97211F\"\n",
    "analyze_network = \"final\"  # options: \"best\", \"final\", <parameter update step no>\n",
    "noise_amplitude = 0.1  # if run analyses with noise, noise amplitude\n",
    "distractor_probability = 1.0\n",
    "show_figures = True  # True if running in jupyter notebook; False if running a .py file\n",
    "running_from_data = True # True if code is running in the data folder next to the model.pth. if false, must run from training file\n",
    "\n",
    "directories = [\n",
    "    \"data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r1/\",\n",
    "    \"data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r3/\",\n",
    "    \"data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r5/\",\n",
    "    \"data/hdgating_and_inversionCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r0/\",\n",
    "    \"data/hdgating_and_reshuffle_fCTRNN_2DIR1O_dr100_n0.1_la0_sa130_e1_dp1.0_r0/\",\n",
    "    \"data/hdgatingCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r0/\",\n",
    "    \"data/hdinversionCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r0/\",\n",
    "    \"data/hdratioCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r0/\",\n",
    "    \"data/hdreshuffle_fCTRNN_2DIR1O_dr100_n0.1_la0_sa130_e1_dp1.0_r0/\",\n",
    "    \"data/hdreshuffle_fCTRNN_2DIR1O_dr100_n0.1_la0_sa130_e1_dp1.0_r1/\",\n",
    "    \"data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp0.0_r0/\",\n",
    "]\n",
    "directories = [\n",
    "    f\"data/hdgating_and_inversionCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r{i}/\" for i in range(10)\n",
    "]\n",
    "directories = [\"data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r3/\"]\n",
    "figure_dir_prefix = \"paper_figures/example_networks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9a973c4-286c-447b-9864-96870ab72075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calc_pref_ave(units_i, timestep_from, timestep_to, to=1, data=None, round_prefs=False, smoothing_constant=0.01):\n",
    "    \"\"\"\n",
    "        Calculate the preferred direction of a given neuron across a window given\n",
    "    \"\"\"\n",
    "    if data is None: data = ao_data\n",
    "    w = torch.sum(data[timestep_from:timestep_to][:, units_i], dim=(0, 4-to)).detach().numpy()\n",
    "    a = np.angle(np.sum(w*np.exp(1j*(np.arange(ORI_SET_SIZE)/ORI_SET_SIZE*2*np.pi)).reshape(1, -1), axis=1)/ (np.sum(np.abs(w), axis=1)+smoothing_constant)) * 180 / np.pi\n",
    "    a[a<0] = a[a<0]+360\n",
    "    a = torch.tensor(a)\n",
    "    if round_prefs: a = torch.round(a)\n",
    "    return a\n",
    "    \n",
    "def generate_behavioral_figure(behavior_repeats = 10):\n",
    "    \"\"\"\n",
    "        Generates the error rates of the network across the different \"time to distractor\"\n",
    "        values and the Near and Far conditions\n",
    "\n",
    "        behavior_repeats is the number of samples for every condition\n",
    "    \"\"\"\n",
    "    delay1s = np.array([10, 15, 20, 25, 30, 90])\n",
    "    noise_amplitude_c = noise_amplitude*1\n",
    "    \n",
    "    def make_all_integer_directions_batch(delay0, delay1, delay2, resolution=1, distractor_probability=1, repeats=1, condition='near'):\n",
    "        batch = []  # inputs in the batch\n",
    "        batch_labels = []  # target outputs in the batch\n",
    "        output_masks = []  # masks in the batch\n",
    "        for i in range(repeats):\n",
    "            for direction1 in np.arange(8)/8*360:\n",
    "                for direction2 in np.arange(8)/8*360:\n",
    "                    diff = direction2-direction1\n",
    "                    if diff < -180: diff += 360\n",
    "                    if diff > 180: diff -= 360\n",
    "                    diff = abs(diff)\n",
    "                    if condition == 'near' and diff != 45: continue\n",
    "                    if condition == 'far' and diff != 135 and diff != 180: continue\n",
    "                    \n",
    "                    i_full, o_full, b_mask = task._make_trial(direction1, direction2, delay0, delay1, delay2, distractor_probability=distractor_probability)\n",
    "                    batch.append(i_full.unsqueeze(0))\n",
    "                    batch_labels.append(o_full.unsqueeze(0))\n",
    "                    output_masks.append(b_mask.unsqueeze(0))\n",
    "        return torch.cat(batch), torch.cat(batch_labels), torch.cat(output_masks)\n",
    "        \n",
    "    repeats = behavior_repeats\n",
    "    errors = {'near': {'rates': [], 'angles': []}, 'far': {'rates': [], 'angles': []}}\n",
    "    for condition in ['near', 'far']:\n",
    "        for delay1 in delay1s:\n",
    "            ao_input, ao_target, ao_mask = make_all_integer_directions_batch(delay0, delay1, delay2, distractor_probability=1, repeats=repeats, condition=condition)\n",
    "            ao_noise_mask = task.get_noise_mask(delay0, delay1, delay2)\n",
    "            ao_noise_mask = ao_noise_mask.repeat(ao_input.shape[0], 1).unsqueeze(2).repeat(1, 1, model.dim_recurrent)  # convert to (batch_size, total_time, dim_recurrent)\n",
    "            ao_noise = torch.randn_like(ao_noise_mask) * ao_noise_mask * noise_amplitude_c\n",
    "            ao_output, ao_h = model.forward(ao_input, noise=ao_noise)\n",
    "            t5 = delay0 + delay2 + task_parameters[\"show_direction_for\"]\n",
    "            t6 = t5 + task_parameters[\"show_cue_for\"]\n",
    "            _, _, e, _ = task.calculate_errors(ao_target, ao_output, ao_mask, t5, t6)\n",
    "            errors[condition]['angles'].append(e)\n",
    "\n",
    "            o1_o, _ = task.convert_sincos_to_angles(ao_output, t5, t6)\n",
    "            o1_t, _ = task.convert_sincos_to_angles(ao_target, t5, t6)\n",
    "            wrong = torch.minimum(torch.minimum(torch.abs(o1_o-o1_t), torch.abs(o1_o-o1_t+360)), torch.abs(o1_o-o1_t-360))>22.5\n",
    "            wrong = torch.sum(wrong, dim=1)>wrong.shape[1]/2\n",
    "            wrong = torch.sum(wrong)/wrong.shape[0]*100\n",
    "            errors[condition]['rates'].append(wrong)\n",
    "\n",
    "    delay1s_labels = delay1s.copy()\n",
    "    delay1s_labels[-1]=40\n",
    "    min_indices = [0, 2, 4, 5]\n",
    "\n",
    "    for suffix2, condition in {'': 'rates', '_angles': 'angles'}.items():\n",
    "        for suffix1, indices in {'': range(len(delay1s)), '_min': min_indices}.items():\n",
    "            fig = plt.figure(figsize=(4, 4))\n",
    "            plt.rc('font', **{'family': 'Arial', 'weight': 'normal', 'size': 14})\n",
    "            plt.plot(delay1s_labels[indices], np.array(errors['near'][condition])[indices], \"k-\", linewidth=2, marker=\"o\", markersize=9, label=\"Near\")\n",
    "            plt.plot(delay1s_labels[indices], np.array(errors['far'][condition])[indices], \"--\", color=\"k\", linewidth=2, marker=\"^\", markersize=10, label=\"Far\")\n",
    "            plt.xlabel(\"time to distractor (ms)\")\n",
    "            if condition == 'rates':\n",
    "                plt.ylabel(\"error rate (%)\")\n",
    "            else:\n",
    "                plt.ylabel(\"average error\", fontsize=17)\n",
    "                plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f°'))\n",
    "                \n",
    "            plt.legend()\n",
    "            plt.ylim(0, max(max(errors['near'][condition]), max(errors['far'][condition]))*1.1)\n",
    "            plt.xlim(6.5, 43.5)\n",
    "            plt.xticks(delay1s_labels[min_indices], delay1s[min_indices]*10)\n",
    "            plt.gca().spines['top'].set_visible(False)\n",
    "            plt.gca().spines['right'].set_visible(False)\n",
    "            plt.savefig(f'{figure_dir_prefix}{directory[5:-1]}_behavior{suffix1}{suffix2}.pdf', bbox_inches='tight')\n",
    "            plt.clf()\n",
    "\n",
    "def generate_activity_figure(vmax=1, trial_input=16, trial_distractor=20):\n",
    "    \"\"\"\n",
    "        Generate a heatmap of activities of all artificial neurons\n",
    "        for an example trial\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(5, 3))\n",
    "    plt.rc('font', **{'family': 'Arial', 'weight': 'normal', 'size': 14})\n",
    "    \n",
    "    timesteps_to_take = np.concatenate((range((t3+t4)//2), range(t4, (t5+t6)//2)))\n",
    "    data_to_show = ao_data[0:t5, torch.cat((DT_i, R1_i, )), trial_input, trial_distractor].T\n",
    "    \n",
    "    plt.imshow(data_to_show*1, cmap='gray_r', vmin=0, vmax=vmax,interpolation='nearest', aspect='auto')\n",
    "    ax = plt.gca()\n",
    "    ax.axvspan(t1, t2, facecolor=targetinput_color, alpha=0.2)\n",
    "    ax.axvspan(t3, t4, facecolor=distractor_color, alpha=0.2)\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    handles.append(mpatches.Patch(color=targetinput_color, alpha=0.3, label='target'))\n",
    "    handles.append(mpatches.Patch(color=distractor_color, alpha=0.3, label='distractor'))\n",
    "    plt.ylabel(\"neuron #\")\n",
    "    plt.xlabel(\"time\")\n",
    "    cb = plt.colorbar(ticks=[0, vmax])\n",
    "    cb.set_label(\"activity\", labelpad=-10)\n",
    "    plt.xticks([0, t1, t3, t5])\n",
    "    plt.xticks([])\n",
    "    plt.xlim(10, t5-60)\n",
    "    ax.legend(fontsize=12, handles=handles, loc=9)\n",
    "    plt.yticks([0, 20, 40, 60, 80, 100])\n",
    "    plt.yticks([])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    plt.savefig(f'{figure_dir_prefix}{directory[5:-1]}_activity.pdf', bbox_inches='tight')\n",
    "    plt.clf()\n",
    "\n",
    "def generate_prefchange_figure():\n",
    "    \"\"\"\n",
    "        Generates the histogram of absolute directional preference change of the artificial neurons\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(3, 3))\n",
    "    plt.rc('font', **{'family': 'Arial', 'weight': 'normal', 'size': 14})\n",
    "    ylim = 99\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    bins = 5\n",
    "    units_i = R1_i\n",
    "    cue_from, cue_to = t1, t2\n",
    "    delay_from, delay_to = t2+20, t3\n",
    "    prefc = _calc_pref_ave(units_i, cue_from, cue_to, to=1)-_calc_pref_ave(units_i, delay_from, delay_to, to=1)\n",
    "    prefc[prefc<-180] = prefc[prefc<-180]+360\n",
    "    prefc[prefc>180] = prefc[prefc>180]-360\n",
    "    prefc = torch.abs(prefc)\n",
    "    hist = torch.histc(prefc, bins = bins, min = 0, max = 180)\n",
    "    hist /= torch.sum(hist)\n",
    "    x = torch.arange(bins)/bins * 180\n",
    "    ax.bar(x*1.033+16, hist*100, align='center', width=180/bins/1.05, color=\"green\")\n",
    "    plt.gca().xaxis.set_major_formatter(FormatStrFormatter('%d°'))\n",
    "    ax.set_xlabel('preference change')\n",
    "    ax.set_ylabel('% of neurons')\n",
    "    ax.set_xticks(torch.arange(0, 181, 45))\n",
    "    ax.set_ylim(0, ylim)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{figure_dir_prefix}{directory[5:-1]}_prefchange.pdf', bbox_inches='tight')\n",
    "    plt.clf()\n",
    "\n",
    "def generate_gif_animation():\n",
    "    \"\"\"\n",
    "        Generates the gif animation of the activities of artificial neurons\n",
    "        in the network for one example trial. A visualization of bump attractor & dynamis\n",
    "    \"\"\"\n",
    "    #TWO RINGS\n",
    "    def make_all_integer_directions_batch(delay0, delay1, delay2, resolution=100, distractor_probability=1):\n",
    "        batch = []  # inputs in the batch\n",
    "        batch_labels = []  # target outputs in the batch\n",
    "        output_masks = []  # masks in the batch\n",
    "        for direction1 in np.arange(resolution)/resolution*360:\n",
    "            for direction2 in [0]:\n",
    "                i_full, o_full, b_mask = task._make_trial(direction1, direction2, delay0, delay1, delay2, distractor_probability=distractor_probability)\n",
    "                batch.append(i_full.unsqueeze(0))\n",
    "                batch_labels.append(o_full.unsqueeze(0))\n",
    "                output_masks.append(b_mask.unsqueeze(0))\n",
    "        return torch.cat(batch), torch.cat(batch_labels), torch.cat(output_masks)\n",
    "    ao_input, ao_target, ao_mask = make_all_integer_directions_batch(delay0, delay1, delay2, distractor_probability=0)\n",
    "    ao_noise_mask = task.get_noise_mask(delay0, delay1, delay2)\n",
    "    ao_noise_mask = ao_noise_mask.repeat(ao_input.shape[0], 1).unsqueeze(2).repeat(1, 1, model.dim_recurrent)  # convert to (batch_size, total_time, dim_recurrent)\n",
    "    ao_noise = torch.randn_like(ao_noise_mask) * ao_noise_mask * 0.1\n",
    "    ao_output, ao_h = model.forward(ao_input, noise=ao_noise)\n",
    "    \n",
    "    def update(t, trial=50):\n",
    "        ax.clear()\n",
    "        r = 1.1\n",
    "        units_i = R1_i\n",
    "        n_bars = len(units_i)\n",
    "        theta = calc_pref(units_i, t3-1, to=1)\n",
    "        x = np.cos(theta*np.pi/180)*r\n",
    "        y = np.sin(theta*np.pi/180)*r\n",
    "        z = np.zeros_like(x)\n",
    "        dx = dy = 0.1 * np.ones_like(z)\n",
    "        dz = torch.maximum(ao_h[trial, t, :][units_i], torch.tensor(0)).detach().numpy()*0.5\n",
    "        if t>=t1 and t<=t2:\n",
    "            ax.bar3d([0], [0], [0], [0.25], [0.25], [0.1], color=\"red\")\n",
    "        ax.bar3d(x, y, z+1, dx, dy, dz, color=\"lightgreen\")\n",
    "        r = 1\n",
    "        units_i = torch.tensor([x for x in range(100) if x not in R1_i])\n",
    "        n_bars = len(units_i)\n",
    "        if n_bars>0:\n",
    "            theta = calc_pref(units_i, t2-1, to=1)\n",
    "            x = np.cos(theta*np.pi/180)*r\n",
    "            y = np.sin(theta*np.pi/180)*r\n",
    "            z = np.zeros_like(x)\n",
    "            dx = dy = 0.1 * np.ones_like(z)\n",
    "            dz = torch.maximum(ao_h[trial, t, :][units_i], torch.tensor(0)).detach().numpy()*0.5\n",
    "            ax.bar3d(x, y, z, dx, dy, dz, color=\"lightblue\")\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.axis('off')\n",
    "        ax.set_zlim(0, 1.5)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ani = FuncAnimation(fig, update, frames=range(t1-10, t3), repeat=True)\n",
    "    writer = PillowWriter(fps=7)\n",
    "    ani.save(f'{figure_dir_prefix}{directory[5:-1]}_animation.gif', writer=writer)\n",
    "    plt.clf()\n",
    "\n",
    "def generate_functional_connectivity_plot(dir_prefix=None):\n",
    "    \"\"\"\n",
    "        Generates the plot\n",
    "    \"\"\"\n",
    "    if dir_prefix is None:\n",
    "        dir_prefix=figure_dir_prefix\n",
    "    lim = 0.1\n",
    "    # function that will be fit to the averaged connection weights\n",
    "    def cosine_fit(x, a, b):\n",
    "        return a * np.cos(x * np.pi / 180) + b\n",
    "    \n",
    "    def get_connplot_graph(units1_id=None, unit1_pref=None, units2_id=None, unit2_pref=None, sm=0):\n",
    "        weight_matrix = None  # different models may store weights differently\n",
    "        try:\n",
    "            weight_matrix = model.fc_h2ah.weight\n",
    "        except:\n",
    "            weight_matrix = model.W_h_ah\n",
    "        distances_weights = {}\n",
    "        distances = []\n",
    "        weights = []\n",
    "        for i in range(len(units1_id)):\n",
    "            for j in range(len(units2_id)):\n",
    "                for k in range(-sm // 2, sm // 2 + 1):\n",
    "                    if j == i: continue\n",
    "                    diff = (unit2_pref[j] - unit1_pref[i]).item()\n",
    "                    if diff > 180: diff -= 360\n",
    "                    if diff < -180: diff += 360\n",
    "                    diff += k\n",
    "                    w_ij = weight_matrix[units2_id[j], units1_id[i]]\n",
    "                    distances.append(diff)\n",
    "                    weights.append(w_ij.item())\n",
    "        return np.array(distances), np.array(weights)\n",
    "    \n",
    "    def get_connplot_iu_graph(units_id, unit_pref, sm=0):\n",
    "        weight_matrix = None  # different models may store weights differently\n",
    "        try:\n",
    "            weight_matrix = model.fc_x2ah.weight\n",
    "        except:\n",
    "            weight_matrix = model.W_x_ah\n",
    "        distances_weights = {}\n",
    "        distances = []\n",
    "        weights = []\n",
    "        for i in range(len(units_id)):\n",
    "            for j in range(task_parameters[\"input_direction_units\"]):\n",
    "                for k in range(-sm // 2, sm // 2 + 1):\n",
    "                    # if j == i: continue\n",
    "                    diff = (unit_pref[i] - round(360 * j / task_parameters[\"input_direction_units\"])).item()\n",
    "                    if diff > 180: diff -= 360\n",
    "                    if diff < -180: diff += 360\n",
    "                    diff += k\n",
    "    \n",
    "                    w_ij = weight_matrix[units_id[i], j]\n",
    "                    distances.append(diff)\n",
    "                    weights.append(w_ij.item())\n",
    "        return np.array(distances), np.array(weights)\n",
    "    \n",
    "    def plot_weights(timestep_from, timestep_to, ax, weights='input', color=\"green\", lim=0.1, fit_curves=True):\n",
    "        if weights=='input':\n",
    "            x, y = get_connplot_iu_graph(R1_i, _calc_pref_ave(R1_i, timestep_from, timestep_to, to=1))\n",
    "        elif weights=='recurrent':\n",
    "            x, y = get_connplot_graph(R1_i, _calc_pref_ave(R1_i, timestep_from, timestep_to, to=1), R1_i, _calc_pref_ave(R1_i, timestep_from, timestep_to, to=1))\n",
    "        bins = np.linspace(-180, 180, 20)\n",
    "        x_binned = []\n",
    "        y_binned = []\n",
    "        sem_binned = []\n",
    "        bin_ids = np.digitize(x, bins)\n",
    "        for i in range(1, len(bins)):\n",
    "            x_binned.append(np.mean(x[bin_ids == i]))\n",
    "            y_binned.append(np.mean(y[bin_ids == i]))\n",
    "            sem_binned.append(scipy.stats.sem(y[bin_ids == i]))\n",
    "        x_binned, y_binned, sem_binned = np.array(x_binned), np.array(y_binned), np.array(sem_binned) * 1.96\n",
    "        ax.axhline(y=0.0, color='gray', linestyle='--', linewidth=2)\n",
    "        ax.fill_between(x_binned, y_binned - sem_binned, y_binned + sem_binned, color=color, alpha=0.3, linewidth=0)\n",
    "        ax.plot(x_binned, y_binned, \"-\", color=color, linewidth=3)\n",
    "        ax.set_xlim(-180, 180)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.set_ylim(-lim * 1.1, lim * 1.1)\n",
    "        ax.set_yticks([-lim, 0, lim])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([-180, 0, 180])\n",
    "        ax.xaxis.set_major_formatter(FormatStrFormatter('%d°'))\n",
    "        ax.set_xlabel(\"∆ preferred angle\")\n",
    "        ax.set_yticks([-lim, 0, lim])\n",
    "    \n",
    "        params, covariance = curve_fit(cosine_fit, x_binned, y_binned)\n",
    "        y_fit = cosine_fit(x_binned, *params)\n",
    "        if fit_curves:\n",
    "            ax.plot(x_binned, y_fit, \"--\", color=color, linewidth=3, label=f\"a = {params[0]:.3f}\")\n",
    "        return params\n",
    "\n",
    "    for fit_curves in [True, False]:\n",
    "        fig = plt.figure(figsize=(6, 6))\n",
    "        plt.rc('font', **{'family': 'Arial', 'weight': 'normal', 'size': 14})\n",
    "        ax1 = fig.add_subplot(2, 2, 1)\n",
    "        ax2 = fig.add_subplot(2, 2, 2)\n",
    "        ax3 = fig.add_subplot(2, 2, 3)\n",
    "        ax4 = fig.add_subplot(2, 2, 4)\n",
    "        ax1.set_ylabel(\"weight\")\n",
    "        ax3.set_ylabel(\"weight\")\n",
    "        params_recurrent_cue = plot_weights(t1, t2, ax1, weights='recurrent', color=\"gray\", lim=lim, fit_curves=fit_curves)\n",
    "        params_recurrent_delay = plot_weights(t2+20, t3, ax2, weights='recurrent', color=\"k\", lim=lim, fit_curves=fit_curves)\n",
    "        params_input_cue = plot_weights(t1, t2, ax3, weights='input', color=targetinput_color, lim=lim, fit_curves=fit_curves)\n",
    "        params_input_delay = plot_weights(t2+20, t3, ax4, weights='input', color=distractor_color, lim=lim, fit_curves=fit_curves)\n",
    "        if fit_curves: \n",
    "            for ax in [ax1, ax2, ax3, ax4]: ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_prefix+directory[5:-1] + f\"_connectivity{'_nofit' if not fit_curves else ''}.pdf\", bbox_inches=\"tight\")\n",
    "        plt.clf()\n",
    "    \n",
    "    factors = {\n",
    "        \"structural_factor\": params_recurrent_delay[0] / params_input_cue[0],\n",
    "        \"functional_factor\": params_input_cue[0] / params_input_delay[0]\n",
    "    }\n",
    "    with open(dir_prefix+directory[5:-1] + '_connectivity.json', 'w') as f:\n",
    "        json.dump(factors, f, indent=4)\n",
    "\n",
    "def generate_exampleneuronfr_figure(neuron_i = 19):\n",
    "    # Show one selected neuron\n",
    "    colors = plt.cm.viridis(np.linspace(0, .9, 4))\n",
    "    \n",
    "    fig = plt.figure(figsize=(4, 3))\n",
    "    plt.rc('font', **{'family': 'Arial', 'weight': 'normal', 'size': 14})\n",
    "    \n",
    "    # Loop through subplots to plot each neuron\n",
    "    ax = plt.gca()\n",
    "    data_means = torch.mean(ao_data[:t3, neuron_i, :, :], dim=2)\n",
    "    data_sems = torch.std(ao_data[:t3, neuron_i, :, :], dim=2) / ((data_means.shape[1]-1)**0.5)\n",
    "    conditions = [0, 7, 15, 23]\n",
    "    for j, condition in enumerate(conditions):\n",
    "        color = colors[j]\n",
    "        mean = data_means[:, condition]\n",
    "        sem = data_sems[:, condition]*1.96\n",
    "        ax.fill_between(range(len(data_means)), mean-sem, mean+sem, color=color, alpha=0.3, linewidth=0)\n",
    "        ax.plot(range(len(data_means)), mean, \"-\", linewidth=3, color=color, label=f\"{j}\")\n",
    "    \n",
    "    #ax.set_title(f\"neuron #{neuron_index}\")\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.axvspan(t1, t2, facecolor=\"k\", alpha=0.1)\n",
    "    ax.set_ylabel(\"activity\")\n",
    "    ax.set_xlabel(\"time (ms)\")\n",
    "    ax.set_xticks([t1, t2, t3])\n",
    "    ax.set_xticklabels([0, 100, t3*10])\n",
    "    ax.set_xlim(10, t3+5)\n",
    "    #ax.set_xlim(0, 2.16)\n",
    "    #ax.set_xlim(0, 2.3)\n",
    "    #ax.set_ylim(0, 55)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figure_dir_prefix+directory[5:-1] + f\"_exampleneuron.pdf\", bbox_inches='tight')\n",
    "def generate_exampleneurontuningcurve_figure(neuron_i=19):\n",
    "    cue_from, cue_to = t1, t2\n",
    "    delay_from, delay_to = t2+20, t3\n",
    "    \n",
    "    n_conditions = ORI_SET_SIZE\n",
    "    cue_data_means = np.zeros((n_conditions, ))\n",
    "    cue_data_sems = np.zeros((n_conditions, ))\n",
    "    delay_data_means = np.zeros((n_conditions, ))\n",
    "    delay_data_sems = np.zeros((n_conditions, ))\n",
    "    for i in np.arange(n_conditions):\n",
    "        cue_data = torch.mean(ao_data[cue_from:cue_to, neuron_i, i, :], dim=0)\n",
    "        cue_data_means[i] = torch.mean(cue_data)\n",
    "        cue_data_sems[i] = scipy.stats.sem(cue_data)\n",
    "        delay_data = torch.mean(ao_data[delay_from:delay_to, neuron_i, i, :], dim=0)\n",
    "        delay_data_means[i] = torch.mean(delay_data)\n",
    "        delay_data_sems[i] = scipy.stats.sem(delay_data)\n",
    "    thetas = np.arange(n_conditions)/n_conditions*360\n",
    "    \n",
    "    conditions = np.arange(0, n_conditions, 1)\n",
    "    thetas = thetas[conditions]\n",
    "    cue_data_means = cue_data_means[conditions]\n",
    "    cue_data_sems = cue_data_sems[conditions]\n",
    "    delay_data_means = delay_data_means[conditions]\n",
    "    delay_data_sems = delay_data_sems[conditions]\n",
    "    \n",
    "    thetas = np.hstack((thetas-360, thetas, thetas+360))\n",
    "    cue_data_means = np.hstack((cue_data_means, cue_data_means, cue_data_means))\n",
    "    cue_data_sems = np.hstack((cue_data_sems, cue_data_sems, cue_data_sems))\n",
    "    delay_data_means = np.hstack((delay_data_means, delay_data_means, delay_data_means))\n",
    "    delay_data_sems = np.hstack((delay_data_sems, delay_data_sems, delay_data_sems))\n",
    "    \n",
    "    # cue_data_sems /= np.max(cue_data_means)\n",
    "    # cue_data_means /= np.max(cue_data_means)\n",
    "    # delay_data_sems /= np.max(delay_data_means)\n",
    "    # delay_data_means /= np.max(delay_data_means)\n",
    "    \n",
    "    fig = plt.figure(figsize=(4, 2.5))\n",
    "    plt.rc('font', **{'family': 'Arial', 'weight': 'normal', 'size': 14})\n",
    "    ax = plt.gca()\n",
    "    color=targetinput_color\n",
    "    ax.fill_between(thetas, cue_data_means-cue_data_sems, cue_data_means+cue_data_sems, color=color, alpha=0.3, linewidth=0, label=\"t=cue\")\n",
    "    ax.plot(thetas, cue_data_means, \"-\", linewidth=3, color=color)\n",
    "    color=distractor_color\n",
    "    ax.fill_between(thetas, delay_data_means-delay_data_sems, delay_data_means+delay_data_sems, color=color, alpha=0.3, linewidth=0, label=\"t=delay\")\n",
    "    ax.plot(thetas, delay_data_means, \"-\", linewidth=3, color=color)\n",
    "    \n",
    "    plt.xticks(np.array([-180, 0, 180, 360]))\n",
    "    plt.xlim(-180, 180)\n",
    "    plt.xlabel(\"stimulus angle\")\n",
    "    plt.gca().xaxis.set_major_formatter(FormatStrFormatter('%d°'))\n",
    "    plt.ylim(-.1, .99)\n",
    "    #ax.set_ylim(0, 55)\n",
    "    plt.ylabel(\"activity\")\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figure_dir_prefix+directory[5:-1] + f\"_exampletuningcurve.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "807e0127-f65d-4842-8b18-e9b0757475a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r3/\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _directory in directories:\n",
    "    print(_directory)\n",
    "    directory = _directory\n",
    "    \n",
    "    # Define the file path and module name\n",
    "    file_path = directory + \"task_and_training.py\"  # Change this to your file's path\n",
    "    module_name = 'task_and_training'  # Arbitrary name for the module\n",
    "    # Create a module object\n",
    "    spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    # Load the module into memory and execute it\n",
    "    spec.loader.exec_module(module)\n",
    "    # Inject attributes into the global namespace\n",
    "    for attr in dir(module):\n",
    "        globals()[attr] = getattr(module, attr)\n",
    "    directory = _directory  # it might have been changed by the imported file, so change it back\n",
    "    \n",
    "    with open(f\"{directory}info.json\", 'r', encoding='utf-8') as f:\n",
    "        j = json.load(f)\n",
    "    hyperparameters = j[\"hyperparameters\"]\n",
    "    task_parameters = j[\"task_parameters\"]\n",
    "    model_parameters = j[\"model_parameters\"]\n",
    "    additional_comments = j[\"additional_comments\"]\n",
    "    directory = j[\"directory\"]\n",
    "        \n",
    "    # some noise may be necessary to prevent dividing by 0 in some of the analyses\n",
    "    # if noise_amplitude == 0: noise_amplitude = 0.0001\n",
    "    \n",
    "    task = Task()\n",
    "    model = Model()\n",
    "    if analyze_network.lower() == \"best\": network_filename = \"model_best.pth\"\n",
    "    elif analyze_network.lower() == \"final\": network_filename = f\"model_parameterupdate{hyperparameters['train_for_steps']}.pth\"\n",
    "    else: network_filename = f\"model_parameterupdate{analyze_network}.pth\"\n",
    "    model_state_dict = torch.load(directory+network_filename, map_location=torch.device('cpu'))[\"model_state_dict\"]\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    \n",
    "    resolution = 30\n",
    "    ORI_RES = 360//resolution\n",
    "    ORI_SET = torch.arange(0, 360, ORI_RES)\n",
    "    ORI_SET_SIZE = ORI_SET.shape[0]\n",
    "    \n",
    "    # fix delays at median values for analysis\n",
    "    delay0, delay1, delay2 = task.get_median_delays()\n",
    "    #delay1 = task_parameters[\"delay1_to\"]  # max delay1 (to ensure convergence to final state for analysis)\n",
    "    show_direction_for = task_parameters[\"show_direction_for\"]\n",
    "    show_cue_for = task_parameters[\"show_cue_for\"]\n",
    "    total_time = show_direction_for+show_cue_for+delay0+delay2\n",
    "    t1, t1d = delay0, \"before O1 presented\"\n",
    "    t1_5, t1_5d = delay0+show_direction_for//2, \"amid 01 presentation\"\n",
    "    t2, t2d = delay0+show_direction_for, \"after O1 presented\"\n",
    "    t3, t3d = delay0+show_direction_for+delay1, \"before O2 presented\"\n",
    "    t3_5, t3_5d = delay0+show_direction_for+delay1+show_direction_for//2, \"amid O2 presentation\"\n",
    "    t4, t4d = delay0+show_direction_for+delay1+show_direction_for, \"after O2 presented\"\n",
    "    t5, t5d = delay0+show_direction_for+delay2, \"before go cue\"\n",
    "    t6, t6d = total_time-1, \"at end of task\"\n",
    "    \n",
    "    # run the model on all possible directions \n",
    "    ao_input, ao_target, ao_mask = task.make_all_integer_directions_batch(delay0, delay1, delay2, distractor_probability=distractor_probability, resolution=resolution)\n",
    "    ao_noise_mask = task.get_noise_mask(delay0, delay1, delay2)\n",
    "    ao_noise_mask = ao_noise_mask.repeat(ao_input.shape[0], 1).unsqueeze(2).repeat(1, 1, model.dim_recurrent)  # convert to (batch_size, total_time, dim_recurrent)\n",
    "    ao_noise = torch.randn_like(ao_noise_mask) * ao_noise_mask * noise_amplitude\n",
    "    ao_output, ao_h = model.forward(ao_input, noise=ao_noise)\n",
    "    \n",
    "    # output model errors (with noise and without)\n",
    "    mse_o1, mse_o2, err_o1, err_o2 = task.calculate_errors(ao_target, ao_output, ao_mask, t5, t6)\n",
    "    ao_output_nn, ao_h_nn = model.forward(ao_input, noise=ao_noise*0)\n",
    "    mse_o1_nn, mse_o2_nn, err_o1_nn, err_o2_nn = task.calculate_errors(ao_target, ao_output_nn, ao_mask, t5, t6)\n",
    "    \n",
    "    # for every timestep and every unit, calculate its activity in all trials\n",
    "    ao_data = torch.zeros((total_time, model.dim_recurrent, ORI_SET_SIZE, ORI_SET_SIZE))\n",
    "    for direction1 in range(ORI_SET_SIZE):\n",
    "        for direction2 in range(ORI_SET_SIZE):\n",
    "            o = ao_h[direction1 * ORI_SET_SIZE + direction2]\n",
    "            ao_data[:, :, direction1, direction2] = o\n",
    "            \n",
    "    # detach from autograd\n",
    "    ao_output = ao_output.detach()\n",
    "    ao_h = ao_h.detach()\n",
    "    ao_data = ao_data.detach()\n",
    "    \n",
    "    timestep, timestep_description = t5, t5d\n",
    "    cutoff_criterion = \"box\" # options: ratio, box\n",
    "    ring_cutoff = 2  # if ratio: minumum variance ratio to consider unit a ring unit\n",
    "    min_pri_var = 0.15  # if box: minimum variance in primary direction to consider unit a ring unit\n",
    "    max_sec_var = 0.10  # if box: maximum variance in the other direction to consider unit a ring unit\n",
    "    var_1 = torch.var(torch.mean(ao_data[timestep], dim=2), dim=1)**0.5 + 0.01\n",
    "    var_2 = torch.var(torch.mean(ao_data[timestep], dim=1), dim=1)**0.5 + 0.01\n",
    "    if cutoff_criterion == \"ratio\":\n",
    "        R1_i = torch.where(var_1/var_2 > ring_cutoff)[0]\n",
    "        R2_i = torch.where(var_2/var_1 > ring_cutoff)[0]\n",
    "        DT_i = torch.tensor([x for x in range(model.dim_recurrent) if (x not in R1_i) and (x not in R2_i)], dtype=int)\n",
    "    elif cutoff_criterion == \"box\":\n",
    "        R1_i = torch.where(torch.logical_and(var_1>min_pri_var, var_2<max_sec_var))[0]\n",
    "        R2_i = torch.where(torch.logical_and(var_2>min_pri_var, var_1<max_sec_var))[0]\n",
    "        DT_i = torch.tensor([x for x in range(model.dim_recurrent) if (x not in R1_i) and (x not in R2_i)], dtype=int)\n",
    "    \n",
    "    ##############################################################\n",
    "    \n",
    "    def calc_pref(units_i, timestep=t5, to=1, data=None, round_prefs=False):\n",
    "        if data is None: data = ao_data\n",
    "        w = torch.sum(data[timestep][units_i], dim=3-to).detach().numpy()\n",
    "        a = np.angle(np.sum(w*np.exp(1j*(np.arange(ORI_SET_SIZE)/ORI_SET_SIZE*2*np.pi)).reshape(1, -1), axis=1)/ (np.sum(np.abs(w), axis=1)+0.01)) * 180 / np.pi\n",
    "        a[a<0] = a[a<0]+360\n",
    "        a = torch.tensor(a)\n",
    "        if round_prefs: a = torch.round(a)\n",
    "        return a\n",
    "    prefs_1 = []  # every unit's preferred O1\n",
    "    prefs_2 = []  # every unit's preferred O2\n",
    "    for timestep in range(total_time):\n",
    "        prefs_1.append(calc_pref(range(model.dim_recurrent), timestep=timestep, to=1).unsqueeze(0))\n",
    "        prefs_2.append(calc_pref(range(model.dim_recurrent), timestep=timestep, to=2).unsqueeze(0))\n",
    "    prefs_1 = torch.cat(prefs_1)\n",
    "    prefs_2 = torch.cat(prefs_2)\n",
    "    \n",
    "    # sort units according to their preferred directions (don't sort DT)\n",
    "    R1_pref = prefs_1[t5-1][R1_i]\n",
    "    R2_pref = prefs_2[t5-1][R2_i]\n",
    "    DT_pref = prefs_1[t2-1][DT_i]\n",
    "    R1_i = R1_i.clone()[torch.argsort(R1_pref)]\n",
    "    R1_pref = R1_pref.clone()[torch.argsort(R1_pref)]\n",
    "    R2_i = R2_i.clone()[torch.argsort(R2_pref)]\n",
    "    R2_pref = R2_pref.clone()[torch.argsort(R2_pref)]\n",
    "    DT_i = DT_i.clone()[torch.argsort(DT_pref)]\n",
    "    DT_pref = DT_pref.clone()[torch.argsort(DT_pref)]\n",
    "    order_indices = torch.cat((R1_i, DT_i, R2_i))\n",
    "    \n",
    "    ##############################################################\n",
    "    generate_exampleneuronfr_figure()\n",
    "    generate_exampleneurontuningcurve_figure()\n",
    "    plt.close()\n",
    "    continue\n",
    "    \n",
    "    \n",
    "    if 'backprop' in directory:  # change vmax and pick a different trial to show the effect more clearly\n",
    "        generate_activity_figure(vmax=.7, trial_input=20, trial_distractor=16)\n",
    "    else:\n",
    "        generate_activity_figure()\n",
    "    generate_prefchange_figure()\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485491f-54b9-41dd-aef9-ea65de38b1b7",
   "metadata": {},
   "source": [
    "# (Temporary) Add all structural and functional ratio info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c469cb18-fc3a-4855-b14d-dd560d096c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r0/\n",
      "ERROR >15\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r1/\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r2/\n",
      "ERROR >15\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r3/\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r4/\n",
      "ERROR >15\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r5/\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r6/\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r7/\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r8/\n",
      "ERROR >15\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r9/\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r10/\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r11/\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r12/\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r13/\n",
      "ERROR >15\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r14/\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r15/\n",
      "ERROR >15\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r16/\n",
      "ERROR >15\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r17/\n",
      "ERROR >15\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r18/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/47/5g669ycs2t17c0kkg2_np43m0000gn/T/ipykernel_73287/1567386492.py:308: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig = plt.figure(figsize=(6, 6))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r19/\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r20/\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r21/\n",
      "ERROR >15\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r22/\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r23/\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r24/\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r25/\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r26/\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r27/\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r28/\n",
      "ERROR >15\n",
      "data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r29/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directories = [f\"data/backpropCTRNN_2DIR1O_dr100_n0.1_la0_e1_dp1.0_r{k}/\" for k in range(30)]\n",
    "for _directory in directories:\n",
    "    print(_directory)\n",
    "    directory = _directory\n",
    "    \n",
    "    # Define the file path and module name\n",
    "    file_path = directory + \"task_and_training.py\"  # Change this to your file's path\n",
    "    module_name = 'task_and_training'  # Arbitrary name for the module\n",
    "    # Create a module object\n",
    "    spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    # Load the module into memory and execute it\n",
    "    spec.loader.exec_module(module)\n",
    "    # Inject attributes into the global namespace\n",
    "    for attr in dir(module):\n",
    "        globals()[attr] = getattr(module, attr)\n",
    "    directory = _directory  # it might have been changed by the imported file, so change it back\n",
    "    \n",
    "    with open(f\"{directory}info.json\", 'r', encoding='utf-8') as f:\n",
    "        j = json.load(f)\n",
    "    hyperparameters = j[\"hyperparameters\"]\n",
    "    task_parameters = j[\"task_parameters\"]\n",
    "    model_parameters = j[\"model_parameters\"]\n",
    "    additional_comments = j[\"additional_comments\"]\n",
    "    directory = j[\"directory\"]\n",
    "        \n",
    "    # some noise may be necessary to prevent dividing by 0 in some of the analyses\n",
    "    # if noise_amplitude == 0: noise_amplitude = 0.0001\n",
    "    \n",
    "    task = Task()\n",
    "    model = Model()\n",
    "    if analyze_network.lower() == \"best\": network_filename = \"model_best.pth\"\n",
    "    elif analyze_network.lower() == \"final\": network_filename = f\"model_parameterupdate{hyperparameters['train_for_steps']}.pth\"\n",
    "    else: network_filename = f\"model_parameterupdate{analyze_network}.pth\"\n",
    "    model_state_dict = torch.load(directory+network_filename, map_location=torch.device('cpu'))[\"model_state_dict\"]\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    \n",
    "    resolution = 30\n",
    "    ORI_RES = 360//resolution\n",
    "    ORI_SET = torch.arange(0, 360, ORI_RES)\n",
    "    ORI_SET_SIZE = ORI_SET.shape[0]\n",
    "    \n",
    "    # fix delays at median values for analysis\n",
    "    delay0, delay1, delay2 = task.get_median_delays()\n",
    "    #delay1 = task_parameters[\"delay1_to\"]  # max delay1 (to ensure convergence to final state for analysis)\n",
    "    show_direction_for = task_parameters[\"show_direction_for\"]\n",
    "    show_cue_for = task_parameters[\"show_cue_for\"]\n",
    "    total_time = show_direction_for+show_cue_for+delay0+delay2\n",
    "    t1, t1d = delay0, \"before O1 presented\"\n",
    "    t1_5, t1_5d = delay0+show_direction_for//2, \"amid 01 presentation\"\n",
    "    t2, t2d = delay0+show_direction_for, \"after O1 presented\"\n",
    "    t3, t3d = delay0+show_direction_for+delay1, \"before O2 presented\"\n",
    "    t3_5, t3_5d = delay0+show_direction_for+delay1+show_direction_for//2, \"amid O2 presentation\"\n",
    "    t4, t4d = delay0+show_direction_for+delay1+show_direction_for, \"after O2 presented\"\n",
    "    t5, t5d = delay0+show_direction_for+delay2, \"before go cue\"\n",
    "    t6, t6d = total_time-1, \"at end of task\"\n",
    "    \n",
    "    # run the model on all possible directions \n",
    "    ao_input, ao_target, ao_mask = task.make_all_integer_directions_batch(delay0, delay1, delay2, distractor_probability=distractor_probability, resolution=resolution)\n",
    "    ao_noise_mask = task.get_noise_mask(delay0, delay1, delay2)\n",
    "    ao_noise_mask = ao_noise_mask.repeat(ao_input.shape[0], 1).unsqueeze(2).repeat(1, 1, model.dim_recurrent)  # convert to (batch_size, total_time, dim_recurrent)\n",
    "    ao_noise = torch.randn_like(ao_noise_mask) * ao_noise_mask * noise_amplitude\n",
    "    ao_output, ao_h = model.forward(ao_input, noise=ao_noise)\n",
    "    \n",
    "    # output model errors (with noise and without)\n",
    "    mse_o1, mse_o2, err_o1, err_o2 = task.calculate_errors(ao_target, ao_output, ao_mask, t5, t6)\n",
    "    ao_output_nn, ao_h_nn = model.forward(ao_input, noise=ao_noise*0)\n",
    "    mse_o1_nn, mse_o2_nn, err_o1_nn, err_o2_nn = task.calculate_errors(ao_target, ao_output_nn, ao_mask, t5, t6)\n",
    "    \n",
    "    # for every timestep and every unit, calculate its activity in all trials\n",
    "    ao_data = torch.zeros((total_time, model.dim_recurrent, ORI_SET_SIZE, ORI_SET_SIZE))\n",
    "    for direction1 in range(ORI_SET_SIZE):\n",
    "        for direction2 in range(ORI_SET_SIZE):\n",
    "            o = ao_h[direction1 * ORI_SET_SIZE + direction2]\n",
    "            ao_data[:, :, direction1, direction2] = o\n",
    "            \n",
    "    # detach from autograd\n",
    "    ao_output = ao_output.detach()\n",
    "    ao_h = ao_h.detach()\n",
    "    ao_data = ao_data.detach()\n",
    "    \n",
    "    timestep, timestep_description = t5, t5d\n",
    "    cutoff_criterion = \"box\" # options: ratio, box\n",
    "    ring_cutoff = 2  # if ratio: minumum variance ratio to consider unit a ring unit\n",
    "    min_pri_var = 0.15  # if box: minimum variance in primary direction to consider unit a ring unit\n",
    "    max_sec_var = 0.10  # if box: maximum variance in the other direction to consider unit a ring unit\n",
    "    var_1 = torch.var(torch.mean(ao_data[timestep], dim=2), dim=1)**0.5 + 0.01\n",
    "    var_2 = torch.var(torch.mean(ao_data[timestep], dim=1), dim=1)**0.5 + 0.01\n",
    "    if cutoff_criterion == \"ratio\":\n",
    "        R1_i = torch.where(var_1/var_2 > ring_cutoff)[0]\n",
    "        R2_i = torch.where(var_2/var_1 > ring_cutoff)[0]\n",
    "        DT_i = torch.tensor([x for x in range(model.dim_recurrent) if (x not in R1_i) and (x not in R2_i)], dtype=int)\n",
    "    elif cutoff_criterion == \"box\":\n",
    "        R1_i = torch.where(torch.logical_and(var_1>min_pri_var, var_2<max_sec_var))[0]\n",
    "        R2_i = torch.where(torch.logical_and(var_2>min_pri_var, var_1<max_sec_var))[0]\n",
    "        DT_i = torch.tensor([x for x in range(model.dim_recurrent) if (x not in R1_i) and (x not in R2_i)], dtype=int)\n",
    "    \n",
    "    ##############################################################\n",
    "    \n",
    "    def calc_pref(units_i, timestep=t5, to=1, data=None, round_prefs=False):\n",
    "        if data is None: data = ao_data\n",
    "        w = torch.sum(data[timestep][units_i], dim=3-to).detach().numpy()\n",
    "        a = np.angle(np.sum(w*np.exp(1j*(np.arange(ORI_SET_SIZE)/ORI_SET_SIZE*2*np.pi)).reshape(1, -1), axis=1)/ (np.sum(np.abs(w), axis=1)+0.01)) * 180 / np.pi\n",
    "        a[a<0] = a[a<0]+360\n",
    "        a = torch.tensor(a)\n",
    "        if round_prefs: a = torch.round(a)\n",
    "        return a\n",
    "    prefs_1 = []  # every unit's preferred O1\n",
    "    prefs_2 = []  # every unit's preferred O2\n",
    "    for timestep in range(total_time):\n",
    "        prefs_1.append(calc_pref(range(model.dim_recurrent), timestep=timestep, to=1).unsqueeze(0))\n",
    "        prefs_2.append(calc_pref(range(model.dim_recurrent), timestep=timestep, to=2).unsqueeze(0))\n",
    "    prefs_1 = torch.cat(prefs_1)\n",
    "    prefs_2 = torch.cat(prefs_2)\n",
    "    \n",
    "    # sort units according to their preferred directions (don't sort DT)\n",
    "    R1_pref = prefs_1[t5-1][R1_i]\n",
    "    R2_pref = prefs_2[t5-1][R2_i]\n",
    "    DT_pref = prefs_1[t2-1][DT_i]\n",
    "    R1_i = R1_i.clone()[torch.argsort(R1_pref)]\n",
    "    R1_pref = R1_pref.clone()[torch.argsort(R1_pref)]\n",
    "    R2_i = R2_i.clone()[torch.argsort(R2_pref)]\n",
    "    R2_pref = R2_pref.clone()[torch.argsort(R2_pref)]\n",
    "    DT_i = DT_i.clone()[torch.argsort(DT_pref)]\n",
    "    DT_pref = DT_pref.clone()[torch.argsort(DT_pref)]\n",
    "    order_indices = torch.cat((R1_i, DT_i, R2_i))\n",
    "    \n",
    "    ##############################################################\n",
    "    if err_o1 > 15: \n",
    "        print(\"ERROR >15\")\n",
    "        continue\n",
    "    generate_functional_connectivity_plot(dir_prefix=\"data_json/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492ba74a-b307-4476-9a31-df7df8d9641e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
